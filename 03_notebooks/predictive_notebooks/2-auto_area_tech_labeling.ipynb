{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TOPS = [\n",
    "    \"Sensing_Perception_VehicleUnderstanding\",\n",
    "    \"Communication_Technologies\",\n",
    "    \"Powertrain_Energy_Battery\",\n",
    "    \"Manufacturing_Industrial_AI\",\n",
    "    \"Robotic_Factory_Autonomous_Delivery\",\n",
    "    \"Cybersecurity_Safety_Governance\",\n",
    "]\n",
    "\n",
    "\n",
    "AUTO_AREA_SEEDS = {\n",
    "\n",
    "    # 1) SENSING / PERCEPTION\n",
    "    \"Sensing_Perception_VehicleUnderstanding\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers how a vehicle perceives and reconstructs its surrounding environment \"\n",
    "            \"using sensors such as cameras, radars, lidars and inertial units. The goal is to detect \"\n",
    "            \"lanes, vehicles, pedestrians, obstacles, free space and road structure by combining \"\n",
    "            \"multi-sensor data into a unified spatial representation. It includes object detection, \"\n",
    "            \"segmentation, depth estimation, multi-sensor fusion, 3D mapping, localization and \"\n",
    "            \"environmental scene understanding for driving and navigation.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # 3) CONNECTIVITY / NETWORKS (includes former software & backend aspects)\n",
    "    \"Communication_Technologies\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers all communication between the vehicle, the infrastructure and the cloud. \"\n",
    "            \"It includes cellular connectivity, V2X communication, vehicle-to-cloud data exchange, \"\n",
    "            \"edge and fog computing integration and telematics services. It also spans in-vehicle data \"\n",
    "            \"routing to gateways and central compute units, over-the-air update delivery, remote \"\n",
    "            \"diagnostics and large-scale backend platforms that collect, process and distribute \"\n",
    "            \"vehicle data for services and fleet-level coordination.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # 4) POWERTRAIN / ENERGY / BATTERY  (data-driven wording removed)\n",
    "    \"Powertrain_Energy_Battery\": {\n",
    "        \"seed\": (\n",
    "            \"This area addresses how energy is generated, stored, managed and converted into vehicle \"\n",
    "            \"motion. It includes battery management systems, charging strategies, electric motors, \"\n",
    "            \"inverters, regenerative braking, hybrid powertrains, fuel cell systems and thermal \"\n",
    "            \"management. Energy efficiency, range optimisation, degradation and ageing mechanisms, \"\n",
    "            \"and grid-interaction concepts such as vehicle-to-grid belong to this domain.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # 5) MANUFACTURING & INDUSTRIAL AI  (energy & data-driven emphasis removed)\n",
    "    \"Manufacturing_Industrial_AI\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers artificial intelligence applied to vehicle production and factory \"\n",
    "            \"operations. It includes vision-based quality inspection, defect detection, process \"\n",
    "            \"monitoring, predictive maintenance for machines, production line balancing, scheduling, \"\n",
    "            \"and automation of material handling. The focus is on intelligent, efficient and highly \"\n",
    "            \"automated automotive manufacturing systems rather than energy or data analytics.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # 6C) ROBOTIC FACTORY + AUTONOMOUS DELIVERY SYSTEMS (revived cluster)\n",
    "    \"Robotic_Factory_Autonomous_Delivery\": {\n",
    "        \"seed\": (\n",
    "            \"This area focuses on mobile and stationary robots that act as physical agents in factories \"\n",
    "            \"and logistics. It includes robotic assembly in body and final assembly shops, autonomous \"\n",
    "            \"mobile robots and automated guided vehicles for internal warehouse logistics, last-mile \"\n",
    "            \"delivery robots and specialised mobile platforms equipped with end effectors, nozzles or \"\n",
    "            \"stabiliser arms for industrial processing. Fleet coordination, indoor navigation and \"\n",
    "            \"cooperation of multiple robotic units are central topics.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # 7) CYBERSECURITY / SAFETY / GOVERNANCE\n",
    "    \"Cybersecurity_Safety_Governance\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers protection of vehicle electronics, communication links and data against \"\n",
    "            \"attacks and failures, together with governance and safety concepts. It includes secure \"\n",
    "            \"boot and firmware integrity, cryptographic communication and key management, gateways and \"\n",
    "            \"firewalls, intrusion detection and anomaly monitoring, secure over-the-air update \"\n",
    "            \"mechanisms and backend security for connected vehicle services. Functional safety, \"\n",
    "            \"redundancy concepts and compliance with safety and cybersecurity regulations are also \"\n",
    "            \"part of this domain.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TOP_SEEDS_1 = {\n",
    "    \"Lidar_Detection\": \"lidar based 3d object detection\",\n",
    "    \"Radar_FF\": \"automotive mmwave radar feature fusion\",\n",
    "    \"Camera_2D\": \"2d vision object detection yolo fasterrcnn\",\n",
    "    \"Camera_3D\": \"monocular depth estimation and 3d bounding boxes\",\n",
    "    \"Sensor_Fusion\": \"early and late sensor fusion architecture\",\n",
    "    \"Occupancy_Grid\": \"neural implicit occupancy grid mapping\",\n",
    "    \"SLAM\": \"visual inertial slam for autonomous vehicles\",\n",
    "    \"Trajectory_Prediction\": \"vru pedestrian trajectory prediction\",\n",
    "    \"Environment_Modeling\": \"scene graph based driving environment modeling\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_3 = {\n",
    "    \"V2X\": \"v2x communication stack c v2x 5g\",\n",
    "    \"Telematics\": \"automotive telematics data pipeline\",\n",
    "    \"Fleet_AI\": \"fleet management ai optimization\",\n",
    "    \"Traffic_Coordination\": \"cooperative traffic signal coordination\",\n",
    "    \"Ride_Sharing\": \"dynamic ride sharing demand prediction\",\n",
    "    \"Mobility_Platforms\": \"mobility as a service cloud platform\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_4 = {\n",
    "    \"BMS\": \"battery management system diagnostics\",\n",
    "    \"SOC_Estimation\": \"state of charge soc estimation algorithms\",\n",
    "    \"SOH_Estimation\": \"state of health prediction lithium ion\",\n",
    "    \"Thermal_Management\": \"battery thermal management\",\n",
    "    \"Fast_Charging\": \"ev fast charging optimization\",\n",
    "    \"Fuel_Cell\": \"hydrogen fuel cell powertrain control\",\n",
    "    \"Inverter_Control\": \"inverter and motor control algorithms\",\n",
    "    \"V2G\": \"bidirectional charging and vehicle to grid control\",\n",
    "    \"Smart_Charging\": \"smart ev charging v2g integration\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_5 = {\n",
    "        \"Defect_Detection\": \"vision based defect inspection\",\n",
    "    \"Production_AI\": \"production scheduling optimization ai\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_6C = {\n",
    "    \"Digital_Twin\": \"automotive digital twin simulation\",\n",
    "    \"Zonal_Architecture\": \"zonal ee architecture for software defined vehicle\",\n",
    "    \"Central_Compute\": \"central compute node and vehicle soc\",\n",
    "    \"Vehicle_OS\": \"real time vehicle operating system\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_7 = {\n",
    "    \"IDS\": \"intrusion detection system for in vehicle networks\",\n",
    "    \"Secure_Update\": \"secure boot and ota integrity\",\n",
    "    \"Threat_Modeling\": \"automotive threat modeling\",\n",
    "    \"PKI\": \"automotive pki cryptography\",\n",
    "    \"ISO26262\": \"functional safety iso26262 analysis\",\n",
    "    \"SOTIF\": \"intended functionality sotif framework\",\n",
    "    \"Privacy_AI\": \"privacy preserving vehicle data processing\"\n",
    "}\n",
    "AUTO_TOP_SEEDS = {\n",
    "    \"Sensing_Perception_VehicleUnderstanding\": AUTO_TOP_SEEDS_1,\n",
    "    \"Communication_Technologies\": AUTO_TOP_SEEDS_3,\n",
    "    \"Powertrain_Energy_Battery\": AUTO_TOP_SEEDS_4,\n",
    "    \"Manufacturing_Industrial_AI\": AUTO_TOP_SEEDS_5,\n",
    "    \"Robotic_Factory_Autonomous_Delivery\": AUTO_TOP_SEEDS_6C,\n",
    "    \"Cybersecurity_Safety_Governance\": AUTO_TOP_SEEDS_7,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: imports & pathler ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "# Burada senin:\n",
    "# AUTO_TOP8\n",
    "# AUTO_AREA_SEEDS\n",
    "# TECH_SEEDS_1..8 ve TECH_SEEDS\n",
    "# zaten yukarıda tanımlı olsun.\n",
    "\n",
    "DATA_DIR    = Path(\"../../01_data\")\n",
    "CORPUS_PATH = DATA_DIR / \"predictive_model\" / \"df_auto_corpus_labeled.parquet\"\n",
    "OUT_DIR = Path(\"../../01_data\") / \"predictive_model\"\n",
    "\n",
    "MODEL_DIR   = Path(\"../../04_models/predictive_techname\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EMB_PATH    = MODEL_DIR / \"doc_embeddings_area_base.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: df yükle, filtrele, AREA ataması + embedding ===\n",
    "\n",
    "df_full = pd.read_parquet(CORPUS_PATH)\n",
    "print(\"ORIJINAL df shape:\", df_full.shape)\n",
    "print(df_full[\"source_type\"].value_counts(), \"\\n\")\n",
    "\n",
    "# Sadece paper + patent\n",
    "keep_types = [\"paper\", \"patent\"]\n",
    "df = df_full[df_full[\"source_type\"].isin(keep_types)].copy()\n",
    "print(\"Sadece paper + patent df shape:\", df.shape)\n",
    "print(df[\"source_type\"].value_counts(), \"\\n\")\n",
    "\n",
    "# ----- AREA encoder -----\n",
    "encoder_area = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "print(\"Encoder dim:\", encoder_area.get_sentence_embedding_dimension())\n",
    "\n",
    "# Seed'lerden kategori vektörleri (AUTO_AREA_SEEDS)\n",
    "area_cat_embeddings = {}\n",
    "for label, subdict in AUTO_AREA_SEEDS.items():\n",
    "    texts = list(subdict.values())\n",
    "    emb = encoder_area.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    area_cat_embeddings[label] = emb.mean(axis=0)\n",
    "\n",
    "cat_matrix = np.stack(list(area_cat_embeddings.values()))  # (8, dim)\n",
    "cat_labels = list(area_cat_embeddings.keys())\n",
    "\n",
    "print(\"cat_matrix shape:\", cat_matrix.shape)\n",
    "print(\"cat_labels:\", cat_labels)\n",
    "\n",
    "# ----- Doküman embedding'leri (doc_emb_non) -----\n",
    "texts_non = df[\"text\"].fillna(\"\").tolist()\n",
    "if EMB_PATH.exists():\n",
    "    print(\">> doc_embeddings_area_base.npy bulundu, yükleniyor...\")\n",
    "    doc_emb_non = np.load(EMB_PATH)\n",
    "    if doc_emb_non.shape[0] != len(texts_non):\n",
    "        print(\"!! UYARI: boyut uyuşmuyor, yeniden encode...\")\n",
    "        doc_emb_non = encoder_area.encode(\n",
    "            texts_non,\n",
    "            batch_size=64,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        np.save(EMB_PATH, doc_emb_non)\n",
    "else:\n",
    "    print(\">> doc_embeddings_area_base.npy yok, encode ediliyor...\")\n",
    "    doc_emb_non = encoder_area.encode(\n",
    "        texts_non,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    np.save(EMB_PATH, doc_emb_non)\n",
    "\n",
    "print(\"Final doc_emb_non shape:\", doc_emb_non.shape)\n",
    "assert doc_emb_non.shape[0] == len(texts_non)\n",
    "\n",
    "# ----- AUTO_AREA_SEEDS ile AREA tahmini -----\n",
    "sims = doc_emb_non @ cat_matrix.T   # (N_docs, 8)\n",
    "rows = np.arange(sims.shape[0])\n",
    "\n",
    "top1_idx    = sims.argmax(axis=1)\n",
    "top1_scores = sims[rows, top1_idx]\n",
    "top1_labels = [cat_labels[i] for i in top1_idx]   # '1_Sensing_...' vs.\n",
    "\n",
    "# df'ye yaz\n",
    "df[\"auto_top8_pred\"] = top1_labels\n",
    "df[\"seed_top1_sim\"]  = top1_scores\n",
    "\n",
    "# Numeric prefix'i ayır: label (1..8) + isim (TECH_SEEDS ile uyumlu)\n",
    "df[\"auto_focus_label\"] = (\n",
    "    df[\"auto_top8_pred\"].astype(str)\n",
    "    .str.extract(r\"^\\s*(\\d+)\", expand=False)\n",
    ")\n",
    "\n",
    "df[\"auto_focus_area\"] = (\n",
    "    df[\"auto_top8_pred\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^\\s*\\d+\\s*[_\\-]\\s*\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "print(\"AREA dağılımı (paper+patent):\")\n",
    "print(df[\"auto_focus_area\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: UMAP 2D (tek kez), df_umap oluştur ===\n",
    "\n",
    "umap_2d = UMAP(\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    "    n_neighbors=40,\n",
    "    min_dist=0.1,\n",
    ")\n",
    "\n",
    "X_2d = umap_2d.fit_transform(doc_emb_non)\n",
    "\n",
    "df_umap = (\n",
    "    df.reset_index()\n",
    "    .rename(columns={\"index\": \"orig_index\"})\n",
    "    .assign(\n",
    "        x_2d=X_2d[:, 0],\n",
    "        y_2d=X_2d[:, 1],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"UMAP için doküman sayısı:\", len(df_umap))\n",
    "print(df_umap[\"auto_focus_area\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66766200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_vertical(text, max_len=40):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return \"<br>\".join(\n",
    "        [text[i:i+max_len] for i in range(0, len(text), max_len)]\n",
    "    )\n",
    "\n",
    "df_umap[\"text_vertical\"] = df_umap[\"text\"].apply(wrap_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2615332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Referans – sadece AREA renkli UMAP ===\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_umap,\n",
    "    x=\"x_2d\",\n",
    "    y=\"y_2d\",\n",
    "    color=\"auto_focus_area\",\n",
    "    hover_data=[\"source_type\",\"text_vertical\", \"auto_focus_area\"],\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(size=5, opacity=0.7),\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=12,\n",
    "        align=\"left\"\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=2200,\n",
    "    height=900,\n",
    "    legend_title_text=\"Area\",\n",
    "    dragmode=\"pan\",\n",
    "    xaxis=dict(autorange=True, fixedrange=False),\n",
    "    yaxis=dict(autorange=True, fixedrange=False),\n",
    ")\n",
    "\n",
    "fig.show(config={\"scrollZoom\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: TECH_SEEDS ile her AREA içinde auto_tech_cluster ata ===\n",
    "\n",
    "TECH_MATRICES = {}\n",
    "TECH_LABELS   = {}\n",
    "\n",
    "for area, tech_dict in AUTO_TOP_SEEDS.items():\n",
    "    labels = list(tech_dict.keys())\n",
    "    texts  = list(tech_dict.values())\n",
    "\n",
    "    emb = encoder_area.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    TECH_MATRICES[area] = emb\n",
    "    TECH_LABELS[area]   = labels\n",
    "\n",
    "print(\"Tech matrices hazır. Alan sayısı:\", len(TECH_MATRICES))\n",
    "\n",
    "tech_preds = []\n",
    "\n",
    "for i, row in enumerate(df_umap.itertuples()):\n",
    "    area = row.auto_focus_area  # Örn: 'Software_Defined_Vehicle_Computing'\n",
    "\n",
    "    tech_matrix = TECH_MATRICES.get(area)\n",
    "    labels      = TECH_LABELS.get(area)\n",
    "\n",
    "    if tech_matrix is None or labels is None:\n",
    "        tech_preds.append(None)\n",
    "        continue\n",
    "\n",
    "    text_emb = doc_emb_non[i]           # (dim,)\n",
    "    sims     = text_emb @ tech_matrix.T # (n_tech,)\n",
    "    best_idx = int(np.argmax(sims))\n",
    "\n",
    "    tech_preds.append(labels[best_idx])\n",
    "\n",
    "df_umap[\"auto_tech_cluster\"] = tech_preds\n",
    "\n",
    "print(df_umap[[\"auto_focus_area\", \"auto_tech_cluster\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11709479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Area sabit, symbol = tech cluster; adalar birebir aynı ===\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_umap,\n",
    "    x=\"x_2d\",\n",
    "    y=\"y_2d\",\n",
    "    color=\"auto_tech_cluster\",              # Büyük adalar = aynı\n",
    "    symbol=\"auto_tech_cluster\",           # İç parçalanma = tech\n",
    "    hover_data=[\"title\", \"auto_focus_area\", \"auto_tech_cluster\"],\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "fig.update_layout(\n",
    "    width=2200,\n",
    "    height=900,\n",
    "    legend_title_text=\"Area / Tech\",\n",
    "    dragmode=\"pan\",\n",
    "    xaxis=dict(autorange=True, fixedrange=False),\n",
    "    yaxis=dict(autorange=True, fixedrange=False),\n",
    ")\n",
    "\n",
    "fig.show(config={\"scrollZoom\": True})\n",
    "\n",
    "print(\"Granüler UMAP doküman sayısı:\", len(df_umap))\n",
    "print(df_umap[\"auto_focus_area\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_umap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a65bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"year\", \"month\", \"text\", \"source_type\", \"auto_focus_area\", \"auto_tech_cluster\"]\n",
    "\n",
    "df_auto_corpus_area_tech = df_umap[cols].copy()\n",
    "\n",
    "save_path = OUT_DIR / \"df_auto_corpus_area_tech.parquet\"\n",
    "df_auto_corpus_area_tech.to_parquet(save_path)\n",
    "\n",
    "save_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
