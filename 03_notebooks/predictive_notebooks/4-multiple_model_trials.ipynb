{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TOPS = [\n",
    "    \"Perception\",\n",
    "    \"Communication_Technologies\",\n",
    "    \"Energy_Source\",\n",
    "    \"Energy_Storage\",\n",
    "    \"Energy_Management\"\n",
    "    \"Urban_Mobility\",\n",
    "    \"Manufacturing\",\n",
    "    \"Robotics\",\n",
    "    \"Cybersecurity\",\n",
    "    \n",
    "]\n",
    "\n",
    "AUTO_AREA_SEEDS = {\n",
    "    \n",
    "    \"Perception\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers how a vehicle perceives and reconstructs its surrounding environment \"\n",
    "            \"using sensors such as cameras, radars, lidars and inertial units. The goal is to detect \"\n",
    "            \"lanes, vehicles, pedestrians, obstacles, free space and road structure by combining \"\n",
    "            \"multi-sensor data into a unified spatial representation. It includes object detection, \"\n",
    "            \"segmentation, depth estimation, multi-sensor fusion, 3D mapping, localization and \"\n",
    "            \"environmental scene understanding for driving and navigation.\"\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    \"Communication_Technologies\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers all communication between the vehicle, the infrastructure and the cloud. \"\n",
    "            \"It includes cellular connectivity, V2X communication, wireless communication, vehicle-to-cloud data exchange, \"\n",
    "            \"edge and fog computing integration and telematics services. It also spans in-vehicle data \"\n",
    "            \"routing to gateways and central compute units, over-the-air update delivery, remote \"\n",
    "            \"diagnostics and large-scale backend platforms that collect, process and distribute \"\n",
    "            \"vehicle data for services and fleet-level coordination.\"\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    \"Energy_Source\": {\n",
    "        \"seed\": (\n",
    "        \"This area addresses how energy is originally generated. It includes \"\n",
    "        \"electrochemical energy from traction battery cells, advanced chemical based material researches, microscopic molecular and atomic based researches, hydrogen-based fuel cell systems and \"\n",
    "        \"auxiliary renewable sources such as vehicle-integrated solar cells. The focus is on primary \"\n",
    "        \"energy generation principles, conversion efficiency, availability, power density and \"\n",
    "        \"fundamental source-level performance characteristics.\"\n",
    "    )\n",
    "},\n",
    "\n",
    "    \"Energy_Storage\": {\n",
    "        \"seed\": (\n",
    "        \"This area addresses how energy is stored, buffered and preserved inside the vehicle before \"\n",
    "        \"being used for propulsion. It includes Lithium batteries, rechargable batteries, high-voltage battery packs, modular battery \"\n",
    "        \"architectures, hybrid storage systems combining batteries and supercapacitors, and safety \"\n",
    "        \"mechanisms ensuring thermal, electrical and mechanical stability. Degradation, ageing, \"\n",
    "        \"state-of-charge(SOC), state-of-health(SOH), second-life utilisation and usable capacity optimisation \"\n",
    "        \"are central topics of this domain.\"\n",
    "    )\n",
    "},\n",
    "\n",
    "    \"Energy_Management\": {\n",
    "        \"seed\": (\n",
    "        \"This area addresses how stored energy is actively managed, converted into mechanical motion \"\n",
    "        \"and exchanged with external electrical infrastructure. It includes battery management \"\n",
    "        \"systems, thermal control, fast and smart charging strategies, traction inverters, electric \"\n",
    "        \"motor control, regenerative braking and bidirectional grid interaction concepts such as \"\n",
    "        \"vehicle-to-grid and vehicle-to-home. Power flow optimisation, efficiency, grid stability, \"\n",
    "        \"real-time control and system-level energy orchestration belong to this domain.\"\n",
    "    )\n",
    "},\n",
    "\n",
    "    \"Urban_Mobility\": {\n",
    "        \"seed\": (\n",
    "        \"This area addresses city-scale transportation planning, policy design and infrastructure \"\n",
    "        \"It focuses on macro-level \"\n",
    "        \"traffic flow modelling, congestion policy, public transport network design, land-use and \"\n",
    "        \"transport integration, emission regulation, accessibility planning and long-term urban \"\n",
    "        \"mobility investment strategies. It includes demand forecasting for city transport systems, \"\n",
    "        \"equity of access, environmental impact assessment and governance of multimodal transport \"\n",
    "        \"ecosystems at metropolitan scale. Interdisciplinary finance, marketing \"\n",
    "        \"and after-sales markets in mobility and manufacturing industries. It includes credit and \"\n",
    "        \"loan default prediction, customer risk profiling, dynamic pricing, demand forecasting, \"\n",
    "        \"customer churn and loyalty modelling, market segmentation, promotion effectiveness, \"\n",
    "        \"brand impact analysis and aftermarket revenue optimisation.\"\n",
    "    )\n",
    "},\n",
    "\n",
    "    \"Manufacturing\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers artificial intelligence applied to vehicle production and factory \"\n",
    "            \"operations. It includes vision-based quality inspection, defect detection, process \"\n",
    "            \"monitoring, predictive maintenance for machines, production line balancing, scheduling, \"\n",
    "            \"and automation of material handling. The focus is on intelligent, efficient and highly \"\n",
    "            \"automated automotive manufacturing systems rather than energy or data analytics.\"\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    \"Robotics\": {\n",
    "        \"seed\": (\n",
    "            \"This area focuses on mobile and stationary robots that act as physical agents in factories \"\n",
    "            \"and logistics. It includes robotic assembly in body and final assembly shops, autonomous \"\n",
    "            \"mobile robots and automated guided vehicles for internal warehouse logistics, last-mile \"\n",
    "            \"delivery robots and specialised mobile platforms equipped with end effectors, nozzles or \"\n",
    "            \"stabiliser arms for industrial processing. Fleet coordination, indoor navigation and \"\n",
    "            \"cooperation of multiple robotic units are central topics.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    \"Cybersecurity\": {\n",
    "        \"seed\": (\n",
    "            \"This area covers protection of communication links and data against \"\n",
    "            \"attacks and failures, together with governance and safety concepts. It includes secure \"\n",
    "            \"boot and firmware integrity, cryptographic communication, gateways and \"\n",
    "            \"firewalls, intrusion detection, secure over-the-air update \"\n",
    "            \"mechanisms and backend security for connected vehicle services, \"\n",
    "            \"redundancy concepts, and cybersecurity regulations are also \"\n",
    "            \"part of this domain.\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TOP_SEEDS_1 = {\n",
    "    \"Sensor_Fusion\": \"multi sensor fusion architecture combining lidar radar and camera into unified perception outputs\",\n",
    "    \"Occupancy_Grid\": \"spatial occupancy grid mapping for free space and obstacle representation around the vehicle\",\n",
    "    \"SLAM\": \"simultaneous localization and mapping using onboard sensors for ego pose and map building in dynamic traffic\",\n",
    "    \"Trajectory_Prediction\": \"future motion and path prediction of vehicles and vulnerable road users in traffic scenes\",\n",
    "    \"Environment_Modeling\": \"semantic scene and object relationship modeling for a structured driving environment representation\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_2 = {\n",
    "    \"4G\": \"4g lte cellular communication for connected vehicles\",\n",
    "    \"5G\": \"5g cellular communication for ultra low latency vehicle connectivity\",\n",
    "    \"Wireless_Communication\": \"wireless communication protocols for vehicle data transmission\",\n",
    "    \"V2V\": \"vehicle to vehicle direct communication\",\n",
    "    \"V2I\": \"vehicle to infrastructure communication\",\n",
    "    \"Edge_Computing\": \"edge computing for real time vehicle data processing\",\n",
    "    \"Cloud_Computing\": \"cloud computing backend for vehicle data storage and processing\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_3 = {\n",
    "    \"Solar_Cell\": \"photovoltaic solar cells (solar cell, perovskite solar, sensitized solar, organic photovoltaics, silicon solar)\",\n",
    "    \"Electrochemical_Energy\": \"electrochemical energy systems (electrochemical energy, hydrogen evolution)\",\n",
    "    \"Nano_Energy\": \"nanoscale energy systems (nano energy, quantum dots)\",\n",
    "}\n",
    "\n",
    "AUTO_TOP_SEEDS_4 = {\n",
    "    \"Battery_Management_System\": \"battery management and control (battery management bms, battery management system, state charge soc, state health soh, battery state health)\",\n",
    "    \"Battery_Thermal_Management\": \"battery thermal and cooling systems (battery thermal management, thermal management systems)\",\n",
    "}\n",
    "AUTO_TOP_SEEDS_5 = {\n",
    "    \"Smart_Grid\": \"smart grid control and monitoring (smart grid technologies, power grid)\",\n",
    "    \"Distributed_Energy_Resources\": \"distributed energy generation and control, dc based local energy networks (dc microgrid, distributed energy resources)\",\n",
    "    \"V2G_G2V_Technologies\": \"bidirectional vehicle grid interaction (grid v2g technology, vehicle g2v, bidirectional energy)\",\n",
    "    \"Charging_Infrastructure\": \"ev charging systems and network (charging infrastructure)\",\n",
    "     \n",
    "}\n",
    "AUTO_TOP_SEEDS_6 = {\n",
    "    \"Traffic_Planning\": \"urban traffic congestion dynamics (traffic congestion)\",\n",
    "    \"Transport_Infrastructure\": \"urban transport network and infrastructure (transport infrastructure)\",\n",
    "    \"Mobility_Demand_Forecasting\": \"urban travel demand prediction (demand forecasting)\",\n",
    "    \"Micro_Mobility\": \"e-scooters, bikes, e-bikes and small personal transport (micro mobility)\",\n",
    "    }\n",
    "\n",
    "AUTO_TOP_SEEDS_7 = {\n",
    "    \"InLine_Quality_Inspection\": \"inline defect, mistake proofing, error prevention, weld quality inspection (poka yoke, defect detection, weld quality)\",\n",
    "    \"Predictive_Maintenance\": \"vehicle and equipment predictive maintenance (vehicle maintenance, predictive maintenance pd)\",\n",
    "    \"Process_Monitoring_Optimization\": \"real time monitoring and waste minimizing stable processes (real time monitoring, proactively finding deviations, minimizing waste optimizing, quality constant process)\"\n",
    "}\n",
    "\n",
    "AUTO_TOP_SEEDS_8 = {\n",
    "    \"Autonomous_Delivery_Robots\": \"autonomous robotic delivery and last mile transport (automated delivery, robotic delivery shipping)\",\n",
    "    \"AGV_Systems\": \"automated guided vehicles for structured factory and warehouse transport, inventory tracking (automated guided vehicle)\",\n",
    "    \"Hybrid_Modular_Robotics\": \"hybrid and modular robotic system architectures combining multiple robot types into reconfigurable platforms (hybrid modular)\"\n",
    "}\n",
    "AUTO_TOP_SEEDS_9 = { \n",
    "    \"Cyber_Physical_Security\": \"security of cyber physical automotive systems, cryptographic and encryption ciphering, network intrusion detection, cyber attacks (cyber physical)\",\n",
    "    \"InVehicle_Network_Protocols\": \"automotive communication and bus protocols (controller area network, protocols)\",\n",
    "    \"Integrity_Protection\": \"data and message integrity protection mechanisms (integrity protection)\",  \n",
    "}\n",
    "AUTO_TOP_SEEDS = {\n",
    "    \"Perception\": AUTO_TOP_SEEDS_1,\n",
    "    \"Communication_Technologies\": AUTO_TOP_SEEDS_2,\n",
    "    \"Energy_Source\": AUTO_TOP_SEEDS_3,\n",
    "    \"Energy_Storage\": AUTO_TOP_SEEDS_4,\n",
    "    \"Energy_Management\": AUTO_TOP_SEEDS_5,\n",
    "    \"Urban_Mobility\": AUTO_TOP_SEEDS_6,\n",
    "    \"Manufacturing\": AUTO_TOP_SEEDS_7,\n",
    "    \"Robotics\": AUTO_TOP_SEEDS_8,\n",
    "    \"Cybersecurity\": AUTO_TOP_SEEDS_9,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: imports & paths ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "DATA_DIR    = Path(\"../../01_data\")\n",
    "CORPUS_PATH = DATA_DIR / \"predictive_model\" / \"df_auto_corpus_labeled.parquet\"\n",
    "OUT_DIR = Path(\"../../01_data\") / \"predictive_model\"\n",
    "\n",
    "MODEL_DIR   = Path(\"../../04_models/predictive_techname\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EMB_PATH    = MODEL_DIR / \"doc_embeddings_area_base_mp_dirty.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46609937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: data filtering, AREA assignment with doc embeddings & seed embeddings cosine similarity score ===\n",
    "\n",
    "df_full = pd.read_parquet(CORPUS_PATH)\n",
    "\n",
    "print(\"ORIJINAL df shape:\", df_full.shape)\n",
    "print(df_full[\"source_type\"].value_counts(), \"\\n\")\n",
    "\n",
    "\n",
    "keep_types = [\"paper\", \"patent\"]\n",
    "df = df_full[df_full[\"source_type\"].isin(keep_types)].copy()\n",
    "print(\"Sadece paper + patent df shape:\", df.shape)\n",
    "print(df[\"source_type\"].value_counts(), \"\\n\")\n",
    "\n",
    "\n",
    "encoder_area = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "print(\"Encoder dim:\", encoder_area.get_sentence_embedding_dimension())\n",
    "\n",
    "\n",
    "area_cat_embeddings = {}\n",
    "for label, subdict in AUTO_AREA_SEEDS.items():\n",
    "    texts = list(subdict.values())\n",
    "    emb = encoder_area.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    area_cat_embeddings[label] = emb.mean(axis=0)\n",
    "\n",
    "cat_matrix = np.stack(list(area_cat_embeddings.values()))  # (8, dim)\n",
    "cat_labels = list(area_cat_embeddings.keys())\n",
    "\n",
    "print(\"cat_matrix shape:\", cat_matrix.shape)\n",
    "print(\"cat_labels:\", cat_labels)\n",
    "\n",
    "\n",
    "texts_non = df[\"text\"].fillna(\"\").tolist()\n",
    "if EMB_PATH.exists():\n",
    "    print(\">> doc_embeddings_area_base.npy bulundu, yükleniyor...\")\n",
    "    doc_emb_non = np.load(EMB_PATH)\n",
    "    if doc_emb_non.shape[0] != len(texts_non):\n",
    "        print(\"!! UYARI: boyut uyuşmuyor, yeniden encode...\")\n",
    "        doc_emb_non = encoder_area.encode(\n",
    "            texts_non,\n",
    "            batch_size=64,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        np.save(EMB_PATH, doc_emb_non)\n",
    "else:\n",
    "    print(\">> doc_embeddings_area_base.npy yok, encode ediliyor...\")\n",
    "    doc_emb_non = encoder_area.encode(\n",
    "        texts_non,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    np.save(EMB_PATH, doc_emb_non)\n",
    "\n",
    "print(\"Final doc_emb_non shape:\", doc_emb_non.shape)\n",
    "assert doc_emb_non.shape[0] == len(texts_non)\n",
    "\n",
    "\n",
    "sims = doc_emb_non @ cat_matrix.T   # (N_docs, 8)\n",
    "rows = np.arange(sims.shape[0])\n",
    "\n",
    "\n",
    "sorted_idx   = np.argsort(sims, axis=1)\n",
    "top1_idx     = sorted_idx[:, -1]\n",
    "top2_idx     = sorted_idx[:, -2]\n",
    "\n",
    "top1_scores  = sims[rows, top1_idx]\n",
    "top2_scores  = sims[rows, top2_idx]\n",
    "\n",
    "top1_labels  = [cat_labels[i] for i in top1_idx]   \n",
    "top2_labels  = [cat_labels[i] for i in top2_idx]\n",
    "\n",
    "# df'ye yaz\n",
    "df[\"auto_top8_pred\"]   = top1_labels\n",
    "df[\"seed_top1_sim\"]    = top1_scores\n",
    "df[\"seed_top2_label\"]  = top2_labels\n",
    "df[\"seed_top2_sim\"]    = top2_scores\n",
    "df[\"margin_pp\"] = df[\"seed_top1_sim\"]-df[\"seed_top2_sim\"]\n",
    "\n",
    "\n",
    "df[\"auto_focus_label\"] = (\n",
    "    df[\"auto_top8_pred\"].astype(str)\n",
    "    .str.extract(r\"^\\s*(\\d+)\", expand=False)\n",
    ")\n",
    "\n",
    "df[\"auto_focus_area\"] = (\n",
    "    df[\"auto_top8_pred\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^\\s*\\d+\\s*[_\\-]\\s*\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "print(\"AREA dağılımı (paper+patent):\")\n",
    "print(df[\"auto_focus_area\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fed755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: CONFIG ===\n",
    "\n",
    "CHOSEN_APPROACH = \"SEED_AREA\"  # \"SEED_AREA\" / \"KMeans_768\" / \"HDBSCAN_768\" / \"GMM_768\" / \"DBSCAN_768\" / \"Agglomerative_768\"\n",
    "UMAP_PARAMS = dict(n_components=2, metric=\"cosine\", random_state=42, n_neighbors=40, min_dist=0.1)\n",
    "\n",
    "PLOT_METHODS = [\"SEED_AREA\", \"KMeans_768\", \"Agglomerative_768\", \"DBSCAN_768\", \"HDBSCAN_768\", \"GMM_768\"]  \n",
    "HOVER_COLS = [\"source_type\",\"title\",\"auto_focus_area\",\"seed_top2_label\",\"margin_pp\",\"seed_top1_sim\",\"seed_top2_sim\"]\n",
    "TOPK_SHOW = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Clustering on 768D doc embeddings (doc_emb_non) + Cache + Metrics + Labels (APPLIED) ===\n",
    "\n",
    "from pathlib import Path\n",
    "import json, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import hdbscan\n",
    "import joblib\n",
    "\n",
    "CACHE_DIR = Path(\"./_cache_clustering_768d\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def _hash_key(payload: dict) -> str:\n",
    "    s = json.dumps(payload, sort_keys=True, default=str).encode(\"utf-8\")\n",
    "    return hashlib.md5(s).hexdigest()\n",
    "\n",
    "def _safe_silhouette(X, labels, metric=\"euclidean\"):\n",
    "    labels = np.asarray(labels)\n",
    "    mask = labels != -1\n",
    "    if mask.sum() < 3:\n",
    "        return np.nan\n",
    "    uniq = np.unique(labels[mask])\n",
    "    if len(uniq) < 2:\n",
    "        return np.nan\n",
    "    return float(silhouette_score(np.asarray(X)[mask], labels[mask], metric=metric))\n",
    "\n",
    "def run_clustering_suite(X, p):\n",
    "    X = np.asarray(X)\n",
    "    rows = []\n",
    "    labels_dict = {}\n",
    "\n",
    "    sil_metric = p.get(\"sil_metric\", \"euclidean\")\n",
    "    cl_metric  = p.get(\"cluster_metric\", p.get(\"metric_name\", \"euclidean\"))\n",
    "\n",
    "    # KMeans\n",
    "    km = KMeans(n_clusters=p[\"n_clusters\"], random_state=42, n_init=10)\n",
    "    lab = km.fit_predict(X)\n",
    "    labels_dict[\"KMeans_768\"] = lab\n",
    "    rows.append({\"method\":\"KMeans_768\", \"n_clusters\": len(np.unique(lab)), \"noise_pct\": 0.0,\n",
    "                 \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    # Agglomerative\n",
    "    ag = AgglomerativeClustering(n_clusters=p[\"n_clusters\"])\n",
    "    lab = ag.fit_predict(X)\n",
    "    labels_dict[\"Agglomerative_768\"] = lab\n",
    "    rows.append({\"method\":\"Agglomerative_768\", \"n_clusters\": len(np.unique(lab)), \"noise_pct\": 0.0,\n",
    "                 \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=p[\"dbscan_eps\"], min_samples=p[\"dbscan_min_samples\"], metric=cl_metric)\n",
    "    lab = db.fit_predict(X)\n",
    "    labels_dict[\"DBSCAN_768\"] = lab\n",
    "    n_noise = float((lab == -1).mean() * 100)\n",
    "    n_cl = len(np.unique(lab)) - (1 if -1 in lab else 0)\n",
    "    rows.append({\"method\":\"DBSCAN_768\", \"n_clusters\": n_cl, \"noise_pct\": n_noise,\n",
    "                 \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    # HDBSCAN\n",
    "    hb = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=p[\"hdb_min_cluster_size\"],\n",
    "        min_samples=p[\"hdb_min_samples\"],\n",
    "        metric=cl_metric,\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        core_dist_n_jobs=-1\n",
    "    )\n",
    "    lab = hb.fit_predict(X)\n",
    "    labels_dict[\"HDBSCAN_768\"] = lab\n",
    "    n_noise = float((lab == -1).mean() * 100)\n",
    "    n_cl = len(np.unique(lab)) - (1 if -1 in lab else 0)\n",
    "    rows.append({\"method\":\"HDBSCAN_768\", \"n_clusters\": n_cl, \"noise_pct\": n_noise,\n",
    "                 \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    # OPTICS (optional)\n",
    "    if p.get(\"enable_optics\", False):\n",
    "        op = OPTICS(\n",
    "            min_samples=p[\"optics_min_samples\"],\n",
    "            xi=p[\"optics_xi\"],\n",
    "            min_cluster_size=p[\"optics_min_cluster_size\"],\n",
    "            metric=cl_metric\n",
    "        )\n",
    "        lab = op.fit_predict(X)\n",
    "        labels_dict[\"OPTICS_768\"] = lab\n",
    "        n_noise = float((lab == -1).mean() * 100)\n",
    "        n_cl = len(np.unique(lab)) - (1 if -1 in lab else 0)\n",
    "        rows.append({\"method\":\"OPTICS_768\", \"n_clusters\": n_cl, \"noise_pct\": n_noise,\n",
    "                     \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    # GMM \n",
    "    gm = GaussianMixture(\n",
    "        n_components=p[\"gmm_n_components\"],\n",
    "        covariance_type=p[\"gmm_covariance_type\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    lab = gm.fit_predict(X)\n",
    "    labels_dict[\"GMM_768\"] = lab\n",
    "    rows.append({\"method\":\"GMM_768\", \"n_clusters\": len(np.unique(lab)), \"noise_pct\": 0.0,\n",
    "                 \"silhouette\": _safe_silhouette(X, lab, metric=sil_metric)})\n",
    "\n",
    "    df_metrics = pd.DataFrame(rows)\n",
    "    df_metrics[\"silhouette\"] = df_metrics[\"silhouette\"].round(3)\n",
    "    df_metrics[\"noise_pct\"]  = df_metrics[\"noise_pct\"].round(1)\n",
    "    return df_metrics, labels_dict\n",
    "\n",
    "\n",
    "# ---- PARAMS (768D) ----\n",
    "SUITE_PARAMS_768 = {\n",
    "    \"n_clusters\": 9,\n",
    "\n",
    "    \"cluster_metric\": \"euclidean\",\n",
    "    \"sil_metric\": \"euclidean\",\n",
    "\n",
    "    \"dbscan_eps\": 0.60,\n",
    "    \"dbscan_min_samples\": 8,\n",
    "\n",
    "    \"hdb_min_cluster_size\": 50,\n",
    "    \"hdb_min_samples\": 5,\n",
    "\n",
    "    \"enable_optics\": False,\n",
    "    \"optics_min_samples\": 12,\n",
    "    \"optics_xi\": 0.05,\n",
    "    \"optics_min_cluster_size\": 0.05,\n",
    "\n",
    "    \"gmm_n_components\": 9,\n",
    "    \"gmm_covariance_type\": \"full\",\n",
    "}\n",
    "\n",
    "X_768 = np.asarray(doc_emb_non)\n",
    "\n",
    "# cache key\n",
    "x_sig = {\"shape\": tuple(X_768.shape), \"mean\": float(X_768.mean()), \"std\": float(X_768.std())}\n",
    "key_payload = {\"suite_params_768\": SUITE_PARAMS_768, \"x_sig\": x_sig}\n",
    "key = _hash_key(key_payload)\n",
    "cache_path = CACHE_DIR / f\"clust_suite_768_{key}.joblib\"\n",
    "\n",
    "if cache_path.exists():\n",
    "    obj = joblib.load(cache_path)\n",
    "    df_metrics_768  = obj[\"df_metrics\"]\n",
    "    labels_dict_768 = obj[\"labels_dict\"]\n",
    "    print(f\">> 768D CACHE HIT: {cache_path.name}\")\n",
    "else:\n",
    "    print(\">> 768D CACHE MISS: clustering 768D çalışıyor, sonra cache'e yazılacak...\")\n",
    "    df_metrics_768, labels_dict_768 = run_clustering_suite(X_768, SUITE_PARAMS_768)\n",
    "    joblib.dump(\n",
    "        {\"df_metrics\": df_metrics_768, \"labels_dict\": labels_dict_768, \"key_payload\": key_payload},\n",
    "        cache_path\n",
    "    )\n",
    "    print(f\">> 768D SAVED: {cache_path.name}\")\n",
    "\n",
    "display(df_metrics_768.sort_values(\"method\").reset_index(drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: GLOBAL SILHOUETTE TABLE (Seed + Clustering Suite) ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# inputs\n",
    "X_768 = np.asarray(doc_emb_non)\n",
    "assert X_768.shape[0] == len(df)\n",
    "\n",
    "\n",
    "labels_seed = df[\"auto_focus_area\"].values\n",
    "sil_seed_global = float(silhouette_score(X_768, labels_seed, metric=\"cosine\"))\n",
    "\n",
    "\n",
    "seed_row = pd.DataFrame([{\n",
    "    \"method\": \"SEED_AREA\",\n",
    "    \"n_clusters\": int(df[\"auto_focus_area\"].nunique()),\n",
    "    \"noise_pct\": 0.0,\n",
    "    \"silhouette\": sil_seed_global\n",
    "}])\n",
    "\n",
    "df_global = pd.concat([df_metrics_768.copy(), seed_row], ignore_index=True)\n",
    "df_global[\"silhouette\"] = df_global[\"silhouette\"].astype(float).round(3)\n",
    "df_global[\"noise_pct\"]  = df_global[\"noise_pct\"].astype(float).round(1)\n",
    "\n",
    "display(df_global.sort_values(\"silhouette\", ascending=False).reset_index(drop=True))\n",
    "print(\"Chosen approach:\", CHOSEN_APPROACH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c585fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Creating UMAP ===\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "umap_2d = UMAP(**UMAP_PARAMS)\n",
    "X_2d = umap_2d.fit_transform(X_768)\n",
    "\n",
    "df_umap = (\n",
    "    df.reset_index()\n",
    "      .rename(columns={\"index\":\"orig_index\"})\n",
    "      .assign(x_2d=X_2d[:,0], y_2d=X_2d[:,1])\n",
    ")\n",
    "\n",
    "# Seed label\n",
    "df_umap[\"SEED_AREA\"] = df_umap[\"auto_focus_area\"]\n",
    "\n",
    "\n",
    "for m, lab in labels_dict_768.items():\n",
    "    df_umap[m] = lab\n",
    "\n",
    "print(\"df_umap:\", df_umap.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f23eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: FIGURES — UMAP2D Scatter Visualisation for each method ===\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "to_plot = [m for m in PLOT_METHODS if m in df_umap.columns]\n",
    "\n",
    "for m in to_plot:\n",
    "    fig = px.scatter(\n",
    "        df_umap,\n",
    "        x=\"x_2d\", y=\"y_2d\",\n",
    "        color=df_umap[m].astype(str),\n",
    "        hover_data=[c for c in HOVER_COLS if c in df_umap.columns],\n",
    "        title=f\"UMAP2D | Labels = {m}\"\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "    fig.update_layout(width=1600, height=850)\n",
    "    fig.show(config={\"scrollZoom\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64918624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: 2D COMPARISON TABLE ===\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "FIG_W, FIG_H = 1700, 980\n",
    "N_COLS = 3\n",
    "\n",
    "BG = \"#f3f4f6\"\n",
    "PLOT_BG = \"#ffffff\"\n",
    "\n",
    "MARKER_SIZE = 3\n",
    "MARKER_OPACITY = 0.75\n",
    "\n",
    "\n",
    "TITLE_SIZE = 20\n",
    "TITLE_COLOR = \"#111827\"\n",
    "\n",
    "METRIC_FONTSIZE = 18     \n",
    "METRIC_COLOR = \"#111827\" \n",
    "\n",
    "\n",
    "HSPACE = 0.07\n",
    "VSPACE = 0.08            \n",
    "\n",
    "SHOW_LEGEND = False\n",
    "\n",
    "\n",
    "ENABLE_ZOOM = True\n",
    "ZOOM_MODE = \"quantile\"\n",
    "Q = 0.95\n",
    "PAD = 0.05\n",
    "\n",
    "HIDE_AXES = True\n",
    "\n",
    "\n",
    "HIGHLIGHT_METHOD = \"SEED_AREA\"\n",
    "HIGHLIGHT_COLOR = \"red\"\n",
    "HIGHLIGHT_WIDTH = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "available = [m for m in PLOT_METHODS if m in df_umap.columns]\n",
    "\n",
    "\n",
    "preferred_order = [\"SEED_AREA\", \"GMM_768\"]\n",
    "to_plot = [m for m in preferred_order if m in available] + [m for m in available if m not in preferred_order]\n",
    "\n",
    "n = len(to_plot)\n",
    "n_rows = math.ceil(n / N_COLS)\n",
    "\n",
    "\n",
    "metrics_lookup = {}\n",
    "\n",
    "if \"df_global\" in globals() and df_global is not None:\n",
    "    tmp = df_global.copy()\n",
    "    tmp[\"method\"] = tmp[\"method\"].astype(str)\n",
    "    metrics_lookup = tmp.set_index(\"method\")[[\"n_clusters\",\"noise_pct\",\"silhouette\"]].to_dict(\"index\")\n",
    "elif \"df_metrics_768\" in globals() and df_metrics_768 is not None:\n",
    "    tmp = df_metrics_768.copy()\n",
    "    tmp[\"method\"] = tmp[\"method\"].astype(str)\n",
    "    metrics_lookup = tmp.set_index(\"method\")[[\"n_clusters\",\"noise_pct\",\"silhouette\"]].to_dict(\"index\")\n",
    "\n",
    "def metric_text(m):\n",
    "    if m in metrics_lookup:\n",
    "        d = metrics_lookup[m]\n",
    "        return f\"clusters: {int(d['n_clusters'])} | noise: {float(d['noise_pct']):.1f}% | sil: {float(d['silhouette']):.3f}\"\n",
    "    return \"clusters: — | noise: — | sil: —\"\n",
    "\n",
    "\n",
    "if ENABLE_ZOOM:\n",
    "    x = df_umap[\"x_2d\"].to_numpy()\n",
    "    y = df_umap[\"y_2d\"].to_numpy()\n",
    "    x0, x1 = np.quantile(x, [(1 - Q) / 2, 1 - (1 - Q) / 2])\n",
    "    y0, y1 = np.quantile(y, [(1 - Q) / 2, 1 - (1 - Q) / 2])\n",
    "    padx = (x1 - x0) * PAD\n",
    "    pady = (y1 - y0) * PAD\n",
    "    XR = [float(x0 - padx), float(x1 + padx)]\n",
    "    YR = [float(y0 - pady), float(y1 + pady)]\n",
    "else:\n",
    "    XR = YR = None\n",
    "\n",
    "\n",
    "subplot_titles = [\n",
    "    f\"{m}<br><span style='font-size:{METRIC_FONTSIZE}px;color:{METRIC_COLOR};'>{metric_text(m)}</span>\"\n",
    "    for m in to_plot\n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n_rows,\n",
    "    cols=N_COLS,\n",
    "    subplot_titles=subplot_titles,\n",
    "    horizontal_spacing=HSPACE,\n",
    "    vertical_spacing=VSPACE\n",
    ")\n",
    "\n",
    "\n",
    "for i, m in enumerate(to_plot):\n",
    "    r = i // N_COLS + 1\n",
    "    c = i % N_COLS + 1\n",
    "\n",
    "    traces = px.scatter(\n",
    "        df_umap,\n",
    "        x=\"x_2d\", y=\"y_2d\",\n",
    "        color=df_umap[m].astype(str),\n",
    "        hover_data=[cc for cc in HOVER_COLS if cc in df_umap.columns],\n",
    "        template=\"plotly_white\",\n",
    "    ).data\n",
    "\n",
    "    for t in traces:\n",
    "        t.marker.size = MARKER_SIZE\n",
    "        t.marker.opacity = MARKER_OPACITY\n",
    "        fig.add_trace(t, row=r, col=c)\n",
    "\n",
    "    if XR is not None and YR is not None:\n",
    "        fig.update_xaxes(range=XR, row=r, col=c)\n",
    "        fig.update_yaxes(range=YR, row=r, col=c)\n",
    "\n",
    "# =========================\n",
    "# LAYOUT\n",
    "# =========================\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    width=FIG_W,\n",
    "    height=FIG_H,\n",
    "    showlegend=SHOW_LEGEND,\n",
    "    paper_bgcolor=BG,\n",
    "    plot_bgcolor=PLOT_BG,\n",
    "    margin=dict(l=30, r=30, t=90, b=30),\n",
    "    font=dict(color=TITLE_COLOR),\n",
    ")\n",
    "\n",
    "if HIDE_AXES:\n",
    "    fig.update_xaxes(visible=False, showgrid=False, zeroline=False)\n",
    "    fig.update_yaxes(visible=False, showgrid=False, zeroline=False)\n",
    "\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(font=dict(color=TITLE_COLOR, size=TITLE_SIZE)))\n",
    "\n",
    "\n",
    "seed_idx = None\n",
    "for i, m in enumerate(to_plot):\n",
    "    if m == HIGHLIGHT_METHOD:\n",
    "        seed_idx = i\n",
    "        break\n",
    "\n",
    "if seed_idx is not None:\n",
    "    sr = seed_idx // N_COLS + 1\n",
    "    sc = seed_idx % N_COLS + 1\n",
    "\n",
    " \n",
    "    axis_num = seed_idx + 1\n",
    "    xref = \"x domain\" if axis_num == 1 else f\"x{axis_num} domain\"\n",
    "    yref = \"y domain\" if axis_num == 1 else f\"y{axis_num} domain\"\n",
    "\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        xref=xref, yref=yref,\n",
    "        x0=0, y0=0, x1=1, y1=1,\n",
    "        line=dict(color=HIGHLIGHT_COLOR, width=HIGHLIGHT_WIDTH),\n",
    "        fillcolor=\"rgba(0,0,0,0)\",\n",
    "        layer=\"above\"\n",
    "    )\n",
    "\n",
    "fig.show(config={\"scrollZoom\": True})\n",
    "fig.write_image(\"umap_grid.png\", width=2400, height=1400, scale=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: DEEP DIVE — Quality metrics for the chosen approach ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X = X_768\n",
    "\n",
    "def seed_area_deep_dive():\n",
    "    \n",
    "    area_to_idx = {a:i for i,a in enumerate(cat_labels)}\n",
    "    areas = df[\"auto_focus_area\"].unique().tolist()\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    labels_all = df[\"auto_focus_area\"].values\n",
    "    sil_global = float(silhouette_score(X, labels_all, metric=\"cosine\"))\n",
    "\n",
    "    for area in areas:\n",
    "        idx = area_to_idx[area]\n",
    "        mask = (df[\"auto_focus_area\"] == area)\n",
    "        if mask.sum() < 10:\n",
    "            continue\n",
    "\n",
    "        top1 = df.loc[mask, \"seed_top1_sim\"].values\n",
    "        top2 = df.loc[mask, \"seed_top2_sim\"].values\n",
    "        margin = top1 - top2\n",
    "\n",
    "        sims_self  = sims[mask.values, idx]\n",
    "        sims_other = np.delete(sims[mask.values], idx, axis=1).mean(axis=1)\n",
    "\n",
    "        binary_labels = (df[\"auto_focus_area\"] == area).astype(int).values\n",
    "        sil_area = float(silhouette_score(X, binary_labels, metric=\"cosine\")) if (10 <= binary_labels.sum() < len(binary_labels)) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"area\": area,\n",
    "            \"n_docs\": int(mask.sum()),\n",
    "            \"mean_top1_sim\": float(np.mean(top1)),\n",
    "            \"std_top1_sim\": float(np.std(top1)),\n",
    "            \"mean_margin\": float(np.mean(margin)),\n",
    "            \"ambiguity_rate_margin<0.05\": float((margin < 0.05).mean()),\n",
    "            \"area_separation_score\": float(np.mean(sims_self - sims_other)),\n",
    "            \"silhouette_area_vs_rest\": float(sil_area),\n",
    "        })\n",
    "\n",
    "    df_area = pd.DataFrame(rows).sort_values([\"silhouette_area_vs_rest\",\"ambiguity_rate_margin<0.05\"], ascending=[True, False])\n",
    "\n",
    "    print(f\"[SEED_AREA] Global silhouette (areas, 768d, cosine): {sil_global:.3f}\")\n",
    "    display(df_area.round(3))\n",
    "\n",
    "    \n",
    "    df_bad = df_area.copy()\n",
    "    df_bad[\"badness\"] = (df_bad[\"ambiguity_rate_margin<0.05\"].fillna(0) - df_bad[\"silhouette_area_vs_rest\"].fillna(0))\n",
    "    df_bad = df_bad.sort_values(\"badness\", ascending=False).head(10)\n",
    "    print(\"\\n[SEED_AREA] Top-10 risky areas):\")\n",
    "    display(df_bad[[\"area\",\"n_docs\",\"silhouette_area_vs_rest\",\"ambiguity_rate_margin<0.05\",\"mean_margin\",\"mean_top1_sim\",\"area_separation_score\"]].round(3))\n",
    "\n",
    "    \n",
    "    if \"margin_pp\" in df.columns:\n",
    "        dfx = df.sort_values(\"margin_pp\", ascending=True).head(TOPK_SHOW).copy()\n",
    "        cols = [c for c in [\"auto_focus_area\",\"margin_pp\",\"seed_top2_label\",\"seed_top1_sim\",\"seed_top2_sim\",\"source_type\",\"title\"] if c in dfx.columns]\n",
    "        print(f\"\\n[SEED_AREA] Less robust {TOPK_SHOW} document (margin_pp low):\")\n",
    "        display(dfx[cols].reset_index(drop=True))\n",
    "\n",
    "    \n",
    "    if \"seed_top2_label\" in df.columns:\n",
    "        conf = (\n",
    "            df.groupby([\"auto_focus_area\",\"seed_top2_label\"])\n",
    "              .size().reset_index(name=\"n\")\n",
    "              .sort_values([\"auto_focus_area\",\"n\"], ascending=[True, False])\n",
    "        )\n",
    "        print(\"\\n[SEED_AREA] Top2 confusion:\")\n",
    "        display(conf.head(50))\n",
    "\n",
    "def clustering_deep_dive(method_name: str):\n",
    "    assert method_name in df_umap.columns, f\"{method_name}\n",
    "    lab = df_umap[method_name].values\n",
    "\n",
    "    \n",
    "    mask = (lab != -1)\n",
    "    sil_global = float(silhouette_score(X[mask], lab[mask], metric=\"cosine\")) if (mask.sum() > 10 and len(np.unique(lab[mask])) > 1) else np.nan\n",
    "\n",
    "    \n",
    "    rows = []\n",
    "    for c in np.unique(lab):\n",
    "        m = (lab == c)\n",
    "        n = int(m.sum())\n",
    "        if c == -1:\n",
    "            rows.append({\"cluster\": int(c), \"n_docs\": n, \"is_noise\": True})\n",
    "            continue\n",
    "\n",
    "        \n",
    "        binary = (lab == c).astype(int)\n",
    "        sil_c = float(silhouette_score(X, binary, metric=\"cosine\")) if (10 <= binary.sum() < len(binary)) else np.nan\n",
    "\n",
    "        \n",
    "        comp = df_umap.loc[m, \"auto_focus_area\"].value_counts(normalize=True).head(3)\n",
    "        comp_str = \" | \".join([f\"{k}:{v:.2f}\" for k,v in comp.items()])\n",
    "\n",
    "        rows.append({\n",
    "            \"cluster\": int(c),\n",
    "            \"n_docs\": n,\n",
    "            \"is_noise\": False,\n",
    "            \"silhouette_cluster_vs_rest\": sil_c,\n",
    "            \"top_area_mix\": comp_str\n",
    "        })\n",
    "\n",
    "    df_cl = pd.DataFrame(rows).sort_values([\"is_noise\",\"n_docs\"], ascending=[True, False])\n",
    "\n",
    "    print(f\"[{method_name}] Global silhouette (noise 제외, 768d, cosine): {sil_global:.3f}\")\n",
    "    display(df_cl.round(3))\n",
    "\n",
    "    \n",
    "    df_bad = df_cl[(df_cl[\"is_noise\"] == False)].copy()\n",
    "    df_bad[\"badness\"] = -df_bad[\"silhouette_cluster_vs_rest\"].fillna(0)\n",
    "    df_bad = df_bad.sort_values(\"badness\", ascending=False).head(10)\n",
    "    print(f\"\\n[{method_name}] Top-10 risky cluster (silhouette low):\")\n",
    "    display(df_bad[[\"cluster\",\"n_docs\",\"silhouette_cluster_vs_rest\",\"top_area_mix\"]].round(3))\n",
    "\n",
    "    \n",
    "    if not df_bad.empty:\n",
    "        worst_c = int(df_bad.iloc[0][\"cluster\"])\n",
    "        dfx = df_umap[df_umap[method_name] == worst_c].copy()\n",
    "        cols = [c for c in [\"orig_index\",method_name,\"auto_focus_area\",\"source_type\",\"title\"] if c in dfx.columns]\n",
    "        print(f\"\\n[{method_name}] Worst cluster={worst_c} samples (first {TOPK_SHOW}):\")\n",
    "        display(dfx[cols].head(TOPK_SHOW).reset_index(drop=True))\n",
    "\n",
    "\n",
    "# ---- RUN chosen deep dive ----\n",
    "if CHOSEN_APPROACH == \"SEED_AREA\":\n",
    "    seed_area_deep_dive()\n",
    "else:\n",
    "    clustering_deep_dive(CHOSEN_APPROACH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
