{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Load the data\n",
    "\n",
    "DATA_DIR    = Path(\"../../01_data\")\n",
    "df = pd.read_parquet(DATA_DIR / \"predictive_model\" /\"df_auto_corpus_area_tech.parquet\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) AREA + high-confidence filter\n",
    "\n",
    "AREA = \"Cybersecurity_Safety_Governance\"\n",
    "\n",
    "\n",
    "mask_pp = df[\"source_type\"].isin([\"paper\", \"patent\"])\n",
    "df[\"margin_pp\"] = df[\"seed_top1_sim\"]-df[\"seed_top2_sim\"]\n",
    "\n",
    "mask_conf = (\n",
    "    (df[\"seed_top1_sim\"] >= 0.60) & (df[\"margin_pp\"] >= 0.1)\n",
    ")\n",
    "\n",
    "mask_area = df[\"auto_focus_area\"] == AREA\n",
    "df_area = df[mask_pp & mask_conf & mask_area].copy()\n",
    "\n",
    "\n",
    "top5 = (\n",
    "    df_area\n",
    "    .sort_values(\"seed_top1_sim\", ascending=False)\n",
    "    .head(5)[\n",
    "        [\"text\", \"seed_top1_sim\", \"auto_focus_area\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n=== AREA most similar 5documents ===\")\n",
    "print(top5.to_string(index=False))\n",
    "print(\"============================================================\\n\")\n",
    "\n",
    "texts = df_area[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "\n",
    "print(f\"AREA: {AREA}\")\n",
    "print(\"Total number of documents:\", len(texts))\n",
    "\n",
    "if len(texts) == 0:\n",
    "    raise ValueError(\"No documents with these filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef62d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) UNIGRAM\n",
    "\n",
    "cv_uni = CountVectorizer(ngram_range=(1,1), min_df=3, stop_words=\"english\")\n",
    "X_uni = cv_uni.fit_transform(texts)\n",
    "unigram_counts = np.asarray(X_uni.sum(axis=0)).ravel()\n",
    "unigram_vocab = cv_uni.get_feature_names_out()\n",
    "\n",
    "df_uni = pd.DataFrame({\n",
    "    \"term\": unigram_vocab,\n",
    "    \"count\": unigram_counts\n",
    "}).sort_values(\"count\", ascending=False)\n",
    "\n",
    "uni_path = f\"word_frequency_unigram_{AREA}.csv\"\n",
    "df_uni.to_csv(uni_path, index=False)\n",
    "print(f\"✓ unigram saved -> {uni_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ae57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) BIGRAM\n",
    "\n",
    "cv_bi = CountVectorizer(ngram_range=(2,2), min_df=3, stop_words=\"english\")\n",
    "X_bi = cv_bi.fit_transform(texts)\n",
    "bigram_counts = np.asarray(X_bi.sum(axis=0)).ravel()\n",
    "bigram_vocab = cv_bi.get_feature_names_out()\n",
    "\n",
    "df_bi = pd.DataFrame({\n",
    "    \"term\": bigram_vocab,\n",
    "    \"count\": bigram_counts\n",
    "}).sort_values(\"count\", ascending=False)\n",
    "\n",
    "bi_path = f\"word_frequency_bigram_{AREA}.csv\"\n",
    "df_bi.to_csv(bi_path, index=False)\n",
    "print(f\"✓ bigram saved -> {bi_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad872d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) TRIGRAM\n",
    "\n",
    "cv_tri = CountVectorizer(ngram_range=(3,3), min_df=3, stop_words=\"english\")\n",
    "X_tri = cv_tri.fit_transform(texts)\n",
    "trigram_counts = np.asarray(X_tri.sum(axis=0)).ravel()\n",
    "trigram_vocab = cv_tri.get_feature_names_out()\n",
    "\n",
    "df_tri = pd.DataFrame({\n",
    "    \"term\": trigram_vocab,\n",
    "    \"count\": trigram_counts\n",
    "}).sort_values(\"count\", ascending=False)\n",
    "\n",
    "tri_path = f\"word_frequency_trigram_{AREA}.csv\"\n",
    "df_tri.to_csv(tri_path, index=False)\n",
    "print(f\"✓ trigram saved -> {tri_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCSV`s saved:\")\n",
    "print(\"-\", uni_path)\n",
    "print(\"-\", bi_path)\n",
    "print(\"-\", tri_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
