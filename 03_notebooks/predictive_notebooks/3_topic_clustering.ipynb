{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: imports & paths ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "\n",
    "CORPUS_PATH = DATA_DIR / \"df_corpus.parquet\"\n",
    "LABELED_PATH = DATA_DIR / \"df_corpus_labeled.parquet\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e477e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: veri ve model ===\n",
    "df_corpus = pd.read_parquet(CORPUS_PATH)\n",
    "df_labeled = pd.read_parquet(LABELED_PATH)\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encoder   = AutoModel.from_pretrained(model_name).to(device)\n",
    "encoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca093ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: embedding fonksiyonu (CLS pooling) ===\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, batch_size=16, max_length=256):\n",
    "    all_vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            list(batch),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        out = encoder(**enc)\n",
    "        # CLS token\n",
    "        cls_vec = out.last_hidden_state[:, 0, :]\n",
    "        all_vecs.append(cls_vec.cpu())\n",
    "    return torch.cat(all_vecs, dim=0).numpy()\n",
    "\n",
    "# Örnek küçük subset ile test\n",
    "test_emb = encode_texts(df_corpus[\"text\"].head(8))\n",
    "test_emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: tüm korpus için embedding (gerekirse batch/bölerek) ===\n",
    "emb_path = DATA_DIR / \"embeddings_scibert.npy\"\n",
    "\n",
    "if emb_path.exists():\n",
    "    embeddings = np.load(emb_path)\n",
    "else:\n",
    "    embeddings = encode_texts(df_corpus[\"text\"].tolist(), batch_size=16, max_length=256)\n",
    "    np.save(emb_path, embeddings)\n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: UMAP boyut indirgeme ===\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=15,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "emb_umap = umap_reducer.fit_transform(embeddings)\n",
    "emb_umap.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ff3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: HDBSCAN ile topic cluster ===\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=50,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\"\n",
    ")\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(emb_umap)\n",
    "df_corpus[\"topic_id\"] = cluster_labels\n",
    "df_corpus[\"topic_id\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: seed tech listesi (tech_names) import ve anchoring ===\n",
    "# tech_names.py içinde mesela:\n",
    "# TECH_SEEDS = [\"quantum sensor\", \"autonomous driving\", \"solid-state battery\", ...]\n",
    "from tech_names import TECH_SEEDS\n",
    "\n",
    "seed_emb = encode_texts(TECH_SEEDS, batch_size=8, max_length=32)\n",
    "seed_umap = umap_reducer.transform(seed_emb)\n",
    "\n",
    "# Basit anchoring: her seed → en yakın topic_id\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "topic_centers = (\n",
    "    pd.DataFrame(emb_umap)\n",
    "    .assign(topic_id=df_corpus[\"topic_id\"].values)\n",
    "    .groupby(\"topic_id\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "topic_ids = topic_centers.index.values\n",
    "topic_vecs = topic_centers.values\n",
    "\n",
    "seed_to_topic = {}\n",
    "for seed, vec in zip(TECH_SEEDS, seed_umap):\n",
    "    dists = cosine_distances(vec.reshape(1, -1), topic_vecs)[0]\n",
    "    best_idx = np.argmin(dists)\n",
    "    seed_to_topic[seed] = int(topic_ids[best_idx])\n",
    "\n",
    "seed_to_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: topic'lara isim atama ===\n",
    "topic_name_map = {}  # {topic_id: \"Quantum Sensors\"} gibi\n",
    "\n",
    "for seed, tid in seed_to_topic.items():\n",
    "    if tid not in topic_name_map:\n",
    "        topic_name_map[tid] = seed\n",
    "    else:\n",
    "        topic_name_map[tid] += \" | \" + seed  # aynı topic'e düşen seedler birleşir\n",
    "\n",
    "df_corpus[\"topic_name\"] = df_corpus[\"topic_id\"].map(topic_name_map).fillna(\"UNKNOWN_TOPIC\")\n",
    "\n",
    "df_corpus[[\"title\", \"source_type\", \"topic_id\", \"topic_name\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: kaydet ===\n",
    "df_corpus.to_parquet(DATA_DIR / \"df_corpus_with_topics.parquet\", index=False)\n",
    "print(\"Saved:\", DATA_DIR / \"df_corpus_with_topics.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
