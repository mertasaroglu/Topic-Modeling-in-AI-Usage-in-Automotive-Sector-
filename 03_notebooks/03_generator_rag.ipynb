{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93446b4",
   "metadata": {},
   "source": [
    "# LLM Response Generation\n",
    "\n",
    "**Why we're doing this:**\n",
    " Take retrieved document chunks and generate coherent answers using a language model.\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Setting up first prototype - done\n",
    "- Setting up the LLM client (Groq/Llama) - to-do\n",
    "- Creating prompt templates for TRL questions - done\n",
    "- Generating answers from retrieved context - done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a9148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ COMPONENTS IMPORTED SUCCESSFULLY!\n",
      "âœ“ TF-IDF retriever loaded successfully\n",
      "âœ“ Template-based RAG answer generator initialized\n",
      "âœ… Generation pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# PERMANENT WORKING IMPORT - USE THIS EVERYWHERE\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "def import_rag_components():\n",
    "    \"\"\"Import RAG components using absolute paths - guaranteed to work\"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Import retriever\n",
    "    retriever_path = os.path.join(current_dir, 'rag_components', 'retriever.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"retriever\", retriever_path)\n",
    "    retriever_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(retriever_module)\n",
    "    \n",
    "    # Import query_interface  \n",
    "    query_interface_path = os.path.join(current_dir, 'rag_components', 'query_interface.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"query_interface\", query_interface_path)\n",
    "    query_interface_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(query_interface_module)\n",
    "    \n",
    "    # Import answer_generator\n",
    "    answer_generator_path = os.path.join(current_dir, 'rag_components', 'answer_generator.py')\n",
    "    spec = importlib.util.spec_from_file_location(\"answer_generator\", answer_generator_path)\n",
    "    answer_generator_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(answer_generator_module)\n",
    "    \n",
    "    return (retriever_module.DocumentAwareRetriever, \n",
    "            query_interface_module.SimpleQueryInterface,\n",
    "            answer_generator_module.RAGAnswerGenerator)\n",
    "\n",
    "# Import the components\n",
    "DocumentAwareRetriever, SimpleQueryInterface, RAGAnswerGenerator = import_rag_components()\n",
    "print(\"ðŸŽ‰ COMPONENTS IMPORTED SUCCESSFULLY!\")\n",
    "\n",
    "# Continue with code\n",
    "VECTOR_INDEX_PATH = \"../04_models/vector_index\"\n",
    "retriever = DocumentAwareRetriever(VECTOR_INDEX_PATH)\n",
    "query_interface = SimpleQueryInterface(retriever)\n",
    "answer_generator = RAGAnswerGenerator(query_interface)\n",
    "print(\"âœ… Generation pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de134455",
   "metadata": {},
   "source": [
    "# Response Quality Setup\n",
    "\n",
    "**Why we're doing this:** \n",
    "Ensure answers are relevant and properly cite sources.\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Formatting retrieved chunks as context - to-do\n",
    "- Adding source citations to responses - to-do\n",
    "- Setting temperature parameters for consistency - to-do\n",
    "\n",
    "**Files accessed:**\n",
    "/models/vector_index/ (FAISS index)\n",
    "/data/processed/chunked_corpus.json (for source metadata)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
